{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_path = os.path.expanduser('~/sparsity/')\n",
    "print(module_path)\n",
    "if module_path not in sys.path: sys.path.append(module_path)\n",
    "from codes.base.inspect import scan_checkpoints\n",
    "from codes.modules.hooks import SpectralObservationPlugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0'\n",
    "threshold_ratio=10\n",
    "path = os.path.expanduser('~/sparsity/runs/T5/from_scratch/sparsified/20230919-221826/save')\n",
    "save_path = os.path.expanduser('~/sparsity/dumps/T5/from_scratch/sparsified/spectral/')\n",
    "log_threshold_nonzero=-1\n",
    "log_r_bound=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(name: str, m: torch.nn.Module):\n",
    "    if 'mlp.linear.0.weight' not in name and 'mlp.0.weight' not in name and 'DenseReluDense.linear.wi.weight' not in name:\n",
    "        return False\n",
    "    print(name)\n",
    "    return True\n",
    "\n",
    "def final(weights):\n",
    "    weight = torch.stack(weights)\n",
    "    res = SpectralObservationPlugin.spectral_properties(\n",
    "        torch.ones([1]).to(device),\n",
    "        weight.to(device),\n",
    "        threshold_ratio\n",
    "    )['kkT']\n",
    "\n",
    "    print(res)\n",
    "\n",
    "    return res\n",
    "\n",
    "def reduction(last_result: 'dict[str, dict[str, torch.Tensor]]', name: str, weight):\n",
    "    if last_result is None: last_result = {}\n",
    "    res: 'dict[str, torch.Tensor]' = SpectralObservationPlugin.spectral_properties(\n",
    "        torch.ones([1]).to(device),\n",
    "        weight.to(device),\n",
    "        threshold_ratio\n",
    "    )['kkT']\n",
    "    # last_result[name] = res\n",
    "    return {\n",
    "        **last_result,\n",
    "        name: res,\n",
    "    }\n",
    "\n",
    "\n",
    "models = [\n",
    "    f'model_{i}.pth' for i in [0, 25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 299]\n",
    "]\n",
    "\n",
    "checkpoint_dirs = [\n",
    "    f'checkpoint-{i}' for i in [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 950000, 100000]\n",
    "]\n",
    "\n",
    "def checkpoint_filter(name: str):\n",
    "    basename = os.path.basename(name)\n",
    "    if basename in models:\n",
    "        return True\n",
    "    if 'pytorch' not in name:\n",
    "        return False\n",
    "    for d in checkpoint_dirs:\n",
    "        if d in name:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "results = scan_checkpoints(\n",
    "    paths=path,\n",
    "    filter=filter,\n",
    "    reduction=reduction,\n",
    "    map_location=device,\n",
    "    checkpoint_filter=checkpoint_filter,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    results_kkT = {int(p[p.find('model_') + len('model_'):-len('.pth')]): value for p, value in results.items()}\n",
    "except ValueError:\n",
    "    results_kkT = {int(p[p.find('checkpoint-') + len('checkpoint-'):p.find('/pytorch_model')]): value for p, value in results.items()}\n",
    "\n",
    "\n",
    "def permute(name):\n",
    "    def get_depth(module_name):\n",
    "        ints = re.findall(r'\\d+', module_name)\n",
    "        return int(ints[0]) + int('decoder' in module_name) * 12\n",
    "        \n",
    "    dict_module_epoch_value = {}\n",
    "    for p, checkpoint in results_kkT.items():\n",
    "        for module, value in checkpoint.items():\n",
    "            depth = get_depth(module)\n",
    "            if depth not in dict_module_epoch_value:\n",
    "                dict_module_epoch_value[depth] = {}\n",
    "            dict_module_epoch_value[depth][p] = value[name]\n",
    "    return dict_module_epoch_value\n",
    "results_kkT = {\n",
    "    name: permute(name) for name in next(iter(next(iter(results_kkT.values())).values()))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_epoch_first(dictionary):\n",
    "    dict_epoch_module_value = {}\n",
    "    for depth, module in dictionary.items():\n",
    "        for epoch, value in module.items():\n",
    "            if epoch not in dict_epoch_module_value:\n",
    "                dict_epoch_module_value[epoch] = {}\n",
    "            dict_epoch_module_value[epoch][depth] = value\n",
    "    return dict_epoch_module_value\n",
    "eigenvalues = permute_epoch_first(results_kkT['eigenvalues'])\n",
    "epochs = list(eigenvalues.keys())\n",
    "epochs, eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = torch.stack([\n",
    "    torch.stack([\n",
    "        value for depth, value in checkpoint.items()       \n",
    "    ])    for epoch, checkpoint in eigenvalues.items()\n",
    "])\n",
    "torch.save(eigenvalues, os.path.join(save_path, 'eigenvalues.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = torch.load(os.path.join(save_path, 'eigenvalues.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_eigenvalue = eigenvalues.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority(value, bins, threshold=0.8, min_bin_index=0):\n",
    "    value = value.cpu()\n",
    "    hist = torch.histogram(value, torch.tensor(bins))\n",
    "    probabilities = hist[0][min_bin_index:] / hist[0][min_bin_index:].sum()\n",
    "    bins = bins[min_bin_index:]\n",
    "    l, r = 0, 0\n",
    "    sum = 0\n",
    "    min_interval = None\n",
    "    while r < len(probabilities):\n",
    "        if sum < threshold and r + 1 >= len(probabilities):\n",
    "            break\n",
    "        while r < len(probabilities) and not (sum >= threshold):\n",
    "            sum += probabilities[r]\n",
    "            r += 1\n",
    "        while l + 1 < r and sum - probabilities[l] >= threshold:\n",
    "            sum -= probabilities[l]\n",
    "            l += 1\n",
    "        if sum >= threshold and (min_interval is None or bins[min_interval[1]] - bins[min_interval[0]] > bins[r] - bins[l]):\n",
    "            min_interval = (int(l), int(r))\n",
    "        sum -= probabilities[l]\n",
    "        l += 1\n",
    "    return bins[min_interval[0]], bins[min_interval[1]]\n",
    "\n",
    "def get_log_and_bins(eigval, n_bins_norms=100, near_zero=False):\n",
    "    log_eigval = eigval.log10()\n",
    "    l, r = log_threshold_nonzero, float(log_eigval.max())\n",
    "    bins_norms = [\n",
    "        i* (r - l) / n_bins_norms + l for i in range(n_bins_norms + 1)\n",
    "    ]\n",
    "    bins_small = [-15, -12, -9, -6] if near_zero else []\n",
    "    bins = bins_small + bins_norms\n",
    "    return log_eigval, bins, get_majority(log_eigval, bins, min_bin_index=len(bins_small))\n",
    "\n",
    "checkpoint = eigenvalues[0]\n",
    "\n",
    "def checkpoint_histogram(checkpoint, save_path=None):\n",
    "    fig, axs = plt.subplots(len(checkpoint), 1, sharex=True)\n",
    "    near_zero_rate = []\n",
    "    majority_width = []\n",
    "    for i, (ax, eigval) in enumerate(zip(axs, checkpoint.cpu())):\n",
    "        if i == len(axs) - 1:\n",
    "            ax.set_xlabel('Log10 Eigenvalue (Non-Zero Only)')\n",
    "        ax.set_xlim([log_threshold_nonzero, log_r_bound])\n",
    "        ax.set_yticks([])\n",
    "        try:\n",
    "            log_eigval, bins, majority = get_log_and_bins(eigval, near_zero=False)\n",
    "            ax.hist(log_eigval, bins=bins, label=f'Layer {i+1} (Non-Zero Only)')\n",
    "            # if i in [0, len(checkpoint) - 1]:\n",
    "                # ax.set_title(f'Layer {i+1}')\n",
    "    \n",
    "            ax.axvline(majority[0], color='red')\n",
    "            ax.axvline(majority[1], color='red')\n",
    "            near_zero_rate.append((log_eigval <= log_threshold_nonzero).float().mean())\n",
    "            majority_width.append(majority[1] - majority[0])\n",
    "        except:\n",
    "            near_zero_rate.append(torch.nan)\n",
    "            majority_width.append(torch.nan)\n",
    "            continue\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    if save_path is None:\n",
    "        fig.show()\n",
    "    else:\n",
    "        fig.savefig(save_path)\n",
    "    \n",
    "    return {\n",
    "        'near_zero_rate': torch.tensor(near_zero_rate),\n",
    "        # 'majority_width': torch.tensor(majority_width),\n",
    "        'ratio': 10**torch.tensor(majority_width)\n",
    "    }\n",
    "\n",
    "def visualize_experiment(epochs, eigenvalues, save_path=None) -> 'dict[int, dict[str, torch.Tensor]]':\n",
    "    statistics = {}\n",
    "    for epoch, checkpoint in zip(epochs, eigenvalues):\n",
    "        single_save_path = os.path.join(save_path, f'eigenvalues_{epoch}.jpg') if save_path is not None else None\n",
    "        single_statistics = checkpoint_histogram(checkpoint, save_path=single_save_path)\n",
    "        statistics[epoch] = single_statistics\n",
    "    return statistics\n",
    "\n",
    "statistics = visualize_experiment(epochs, eigenvalues, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_lines(data, y_label=None, ylim=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot multiple lines based on the provided data structure.\n",
    "\n",
    "    Args:\n",
    "    - data (list): List of tuples. Each tuple consists of a label and a list of (x, y) values.\n",
    "                  e.g. [(label, [(x, y)])]\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract unique labels and assign colors from the Viridis colormap\n",
    "    labels = [item[0] for item in data]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(labels)))\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    if y_label is not None:\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "    for (label, values), color in zip(data, colors):\n",
    "        x_values = [x[0] for x in values]\n",
    "        y_values = [x[1] for x in values]\n",
    "        ax.plot(x_values, y_values, label=f\"Layer {label}\", color=color)\n",
    "        ax.set_xlabel(\"Epochs\" if max(x_values) <= 1000 else \"Steps\") \n",
    "\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.tight_layout()\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "\n",
    "\n",
    "def visualize_changes(statistics: 'dict[int, dict[str, torch.Tensor]]', save_path=None):\n",
    "    epochs = list(statistics.keys())\n",
    "    dict_name_epoch: 'dict[str, dict[int, torch.Tensor]]' = {}\n",
    "    for epoch, checkpoint in statistics.items():\n",
    "        for name, value in checkpoint.items():\n",
    "            if name not in dict_name_epoch:\n",
    "                dict_name_epoch[name] = {}\n",
    "            dict_name_epoch[name][epoch] = value\n",
    "    dict_name_value = {\n",
    "        name: torch.stack([value for epoch, value in indexed_values.items()]) for name, indexed_values in dict_name_epoch.items()\n",
    "    }\n",
    "    dict_name_value = {\n",
    "        **dict_name_value,\n",
    "        'ratio_full': dict_name_value['ratio']\n",
    "    }\n",
    "\n",
    "    ylims = {\n",
    "        'ratio': [0, dict_name_value['ratio'].reshape(-1)[~dict_name_value['ratio'].reshape(-1).isnan()].max() * 1.1],\n",
    "        'ratio_full': [0, dict_name_value['ratio'].reshape(-1)[~dict_name_value['ratio'].reshape(-1).isnan()].max() * 1.1],\n",
    "        'near_zero_rate': [0.7, 1]\n",
    "    }\n",
    "    ylims['ratio'][1] = min(ylims['ratio'][1], 100)\n",
    "\n",
    "    y_labels = {\n",
    "        'ratio': 'Ratio',\n",
    "        'ratio_full': 'Ratio',\n",
    "        'near_zero_rate': 'Near Zero Rate'\n",
    "    }\n",
    "\n",
    "    for name, values in dict_name_value.items():\n",
    "        print(values.shape)\n",
    "        lines = [\n",
    "            (layer_id + 1, sorted([(epochs[epoch_id], float(value)) for epoch_id, value in enumerate(values[:, layer_id])])) \n",
    "                for layer_id in range(0, values.shape[-1])\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "        plot_lines(\n",
    "            lines,\n",
    "            ylim=ylims[name],\n",
    "            y_label=y_labels[name],\n",
    "            save_path=os.path.join(save_path, name + '.jpg') if save_path is not None else None\n",
    "        )\n",
    "\n",
    "visualize_changes(statistics, save_path=save_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mybase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
