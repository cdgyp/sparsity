= 究竟在优化 $norm(A)_2$ 或 $norm(A)_1$ 还是 $sum A_(i j)$？

区别在于如何处理负的激活值

== 使用 S-ReLU

- 在正值处如同 ReLU
- 在负值时，较大值为 $0$，但减小到阈值 interval 后线性下降

实验时使用 interval=1

发现负激活值也减小了

- 但网络的泛化能力很差，训练集正确率接近 1 但测试集只有 0.6
- 稀疏性有被优化，但优化程度不高

下一步尝试 Leaky-ReLU

实验日期 20230527-001238

== 使用 Leaky-ReLU

